#tensorflow to reliaze the differences between RNN, LSTM, and GRU
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import SimpleRNN, LSTM, GRU, Dense
import numpy as np

# ====== 1ï¸âƒ£ ç”Ÿæˆç¤ºä¾‹æ•°æ® ======
# æ ·æœ¬æ•° = 500ï¼Œæ—¶é—´æ­¥ = 20ï¼Œæ¯æ­¥ç‰¹å¾ = 5
X = np.random.random((500, 20, 5))
# äºŒåˆ†ç±»æ ‡ç­¾
y = np.random.randint(0, 2, size=(500, 1))

# ====== 2ï¸âƒ£ å®šä¹‰ä¸‰ç§æ¨¡å‹ç»“æ„ ======

# --- æ™®é€š RNN ---
rnn_model = Sequential([
    SimpleRNN(64, input_shape=(20, 5)),
    Dense(1, activation='sigmoid')
])
rnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# --- LSTM ---
lstm_model = Sequential([
    LSTM(64, input_shape=(20, 5)),
    Dense(1, activation='sigmoid')
])
lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# --- GRU ---
gru_model = Sequential([
    GRU(64, input_shape=(20, 5)),
    Dense(1, activation='sigmoid')
])
gru_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# ====== 3ï¸âƒ£ åˆ†åˆ«è®­ç»ƒä¸‰ä¸ªæ¨¡å‹ ======
print("\nğŸ§  Training Simple RNN...")
rnn_model.fit(X, y, epochs=3, batch_size=32, verbose=1)

print("\nğŸ§  Training LSTM...")
lstm_model.fit(X, y, epochs=3, batch_size=32, verbose=1)

print("\nğŸ§  Training GRU...")
gru_model.fit(X, y, epochs=3, batch_size=32, verbose=1)

# ====== 4ï¸âƒ£ å¯¹æ¯”ç»“æœ ======
print("\nâœ… RNN Evaluation:")
print(rnn_model.evaluate(X, y))

print("\nâœ… LSTM Evaluation:")
print(lstm_model.evaluate(X, y))

print("\nâœ… GRU Evaluation:")
print(gru_model.evaluate(X, y))
